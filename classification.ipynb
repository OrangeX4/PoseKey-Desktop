{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhoQ0WE77laV"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "vasWnqRgy1H4"
      },
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 François Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYysdyb-CaWM"
      },
      "source": [
        "# 基本分类：对服装图像进行分类"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://tensorflow.google.cn/tutorials/keras/classification\" class=\"\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\" class=\"\">在 TensorFlow.org 上查看</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/keras/classification.ipynb\" class=\"\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\" class=\"\">在 Google Colab 中运行</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/keras/classification.ipynb\" class=\"\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\" class=\"\">在 GitHub 上查看源代码</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/tutorials/keras/classification.ipynb\" class=\"\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\" class=\"\">下载笔记本</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbVhjPpzn6BM"
      },
      "source": [
        "本指南将训练一个神经网络模型，对运动鞋和衬衫等服装图像进行分类。即使您不理解所有细节也没关系；这只是对完整 TensorFlow 程序的快速概述，详细内容会在您实际操作的同时进行介绍。\n",
        "\n",
        "本指南使用了 [tf.keras](https://tensorflow.google.cn/guide/keras)，它是 TensorFlow 中用来构建和训练模型的高级 API。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzLKpmZICaWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0e4cf9c-a934-4ad4-e86f-62ad89ac3bcd"
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## 导入 Fashion MNIST 数据集"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLdCchMdCaWQ"
      },
      "source": [
        "本指南使用 [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) 数据集，该数据集包含 10 个类别的 70,000 个灰度图像。这些图像以低分辨率（28x28 像素）展示了单件衣物，如下所示：\n",
        "\n",
        "<table>\n",
        "  <tr><td>     <img alt=\"Fashion MNIST sprite\" src=\"https://tensorflow.google.cn/images/fashion-mnist-sprite.png\" class=\"\"> </td></tr>\n",
        "  <tr><td align=\"center\">     <b>图 1.</b>  <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST 样本</a>（由 Zalando 提供，MIT 许可）。<br>\n",
        "</td></tr>\n",
        "</table>\n",
        "\n",
        "Fashion MNIST 旨在临时替代经典 [MNIST](http://yann.lecun.com/exdb/mnist/) 数据集，后者常被用作计算机视觉机器学习程序的“Hello, World”。MNIST 数据集包含手写数字（0、1、2 等）的图像，其格式与您将使用的衣物图像的格式相同。\n",
        "\n",
        "本指南使用 Fashion MNIST 来实现多样化，因为它比常规 MNIST 更具挑战性。这两个数据集都相对较小，都用于验证某个算法是否按预期工作。对于代码的测试和调试，它们都是很好的起点。\n",
        "\n",
        "在本指南中，我们使用 60,000 个图像来训练网络，使用 10,000 个图像来评估网络学习对图像分类的准确率。您可以直接从 TensorFlow 访问 Fashion MNIST。请运行以下代码，直接从 TensorFlow 中导入和加载 Fashion MNIST 数据："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MqDQO0KCaWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77982dc9-54d0-4289-956c-ad98713611f1"
      },
      "source": [
        "# fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "# (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "r = np.load(\"data.npz\")\n",
        "r.files\n",
        "train_images = r['data'][23:]\n",
        "train_labels = r['label'][23:]\n",
        "\n",
        "test_images = r['data'][:23]\n",
        "test_labels = r['label'][:23]\n",
        "\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 12, 17, 3)\n",
            "(23, 12, 17, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9FDsUlxCaWW"
      },
      "source": [
        "加载数据集会返回四个 NumPy 数组：\n",
        "\n",
        "- `train_images` 和 `train_labels` 数组是*训练集*，即模型用于学习的数据。\n",
        "- *测试集*、`test_images` 和 `test_labels` 数组会被用来对模型进行测试。\n",
        "\n",
        "图像是 28x28 的 NumPy 数组，像素值介于 0 到 255 之间。*标签*是整数数组，介于 0 到 9 之间。这些标签对应于图像所代表的服装*类*：\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>标签</th>\n",
        "    <th>类</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T恤/上衣</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>裤子</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>套头衫</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>连衣裙</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>外套</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>凉鞋</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>衬衫</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>运动鞋</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>包</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>短靴</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "每个图像都会被映射到一个标签。由于数据集不包括*类名称*，请将它们存储在下方，供稍后绘制图像时使用："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjnLH5S2CaWx"
      },
      "source": [
        "class_names = ['stand', 'run']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "## 浏览数据\n",
        "\n",
        "在训练模型之前，我们先浏览一下数据集的格式。以下代码显示训练集中有 60,000 个图像，每个图像由 28 x 28 的像素表示："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW5k_xz1CaWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "075c5f90-c1b0-4297-ed5f-6848d3ec20ec"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 12, 17, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIAcvQqMCaWf"
      },
      "source": [
        "同样，训练集中有 60,000 个标签："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRFYHB2mCaWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11fbf7b0-402e-46a6-80ab-f18c38cb019f"
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSlYxFuRCaWk"
      },
      "source": [
        "每个标签都是一个 0 到 9 之间的整数："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKnCTHz4CaWg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9db01c2f-584f-460f-e3ef-31424629cb6c"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMPI88iZpO2T"
      },
      "source": [
        "测试集中有 10,000 个图像。同样，每个图像都由 28x28 个像素表示："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KFnYlcwCaWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de3adcf3-8458-45ff-97ca-e7a0819df173"
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23, 12, 17, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd0A0Iu0CaWq"
      },
      "source": [
        "测试集包含 10,000 个图像标签："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJmPr5-ACaWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a123396c-3e86-4587-d06a-6629d094858e"
      },
      "source": [
        "len(test_labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "## 预处理数据\n",
        "\n",
        "在训练网络之前，必须对数据进行预处理。如果您检查训练集中的第一个图像，您会看到像素值处于 0 到 255 之间："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4VEw8Ud9Quh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "ef7ef90d-e01a-48e2-fefb-b89841251626"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADtCAYAAACBOK/+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXhklEQVR4nO3de7BeVX3G8e9zcjsQQricQDAJEDVqKW0Fz4CIoygXA3VIL7QFL0VFM3bE4q2KYwcc+k9bK/ZGaaNSraVSxVtmGg2Uytg6ggREyEUkgMqJgRCuSiA5531//ePdJ7y8nsvOu/bZe7N5PjN7zntZa6919rvP76x37bXWVkRgZmblG6i6AmZmz1cOwGZmFXEANjOriAOwmVlFHIDNzCoyu+oKmJnNhDe8bn48/EgrV9pb79i9PiJWznCVfoUDsJk10sOPtPj++iNzpZ11xN1DM1ydCTkAm1kjBdCmXXU1puQAbGaNFASjka8LoioOwGbWWG4Bm5lVIAhaNV9qwQHYzBqrjQOwmVnpAmg5AJuZVcMtYDOzCgQw6j5gM7PyBeEuCDOzSgS06h1/HYDNrJk6M+HqzQHYzBpKtFDVlZiSA7CZNVLnIpwD8F5Dg4qjFvS/BLEG0r5QRCvhwxhM+yDveyot/wsPnJeUv/XYrL7zDiyam1T22ANpy07PHhpMyt96MOGcOyit7u0n087ZuxenHfuB2f2vhbB7dP+kskmrOmMbN+6MiEX95u+MA3YA3uuoBQN89/f26zv/vP2fSip/7LH+f9142Zykst98R9rZeM3KFyflf+IbB/add/93HZVU9s5PpP0hH/rOlyXlf+LyhHNuVdo/vl037UrKv/Ijy5PyLzj00b7zbt3xiqSyY0naFbAdK17806QdAG23gM3MyucWsJlZRQLRqvld15JqJ2mlpLskbZV0cVGVMjMrQjuUa6tK3y1gSbOAK4DTgRHgFklrI2JzUZUzM+tXIPZE/xefy5DSAj4B2BoR90bEHuAaYFUx1TIzS9OZiDGQa6tKSh/wEuD+rucjwIm9iSStBlYDLDug3h3iZtYsz/uLcBGxBlgD8IpFs2o+M9vMmiJCtKLeF+FSAvA2YFnX86XZa2ZmtdBucAv4FmCFpOV0Au+5wJsKqZWZWaLORbh6j7Ttu3YRMSbpQmA9MAu4KiI2FVYzM7ME4xfh6izp30NErAPWFVQXM7NCtTwV2cysfM+FmXAOwGbWWO0Gj4Loi1K+ESR+m0iZcpj6OR6WWvnU3z1hKc7ReWmjB2clrku4O/G+BvMSWkGhtJlU+yltFb2hxCVYFyYcu5HE+6lVfTugzmI8DsBmZqULxGjNpyI7AJtZI0XQ6IkYZmY1pkZPxDAzq63ALWAzs8r4IpyZWQWCahdbz8MB2MwaqXNb+nqHuHrXzsysb/J6wGZmVQg8E87MrDJ1bwHX+9+DmVmfIkQ7BnJteUx3F3hJR0r6tqQfSLpD0lnT7dMtYDNrpM5FuGKmIue8C/yfA1+KiCslHUNnqd6jp9qvA7CZNVSh94Tbexd4AEnjd4HvDsABHJg9Xgj8fLqdOgCbWSN1LsLl7gMekrSh6/ma7IbC4/LcBf7jwHWS3gvMB06brlAHYDNrrH2YCbczIoYTizsP+FxEfFLSScAXJB0bEZOuCVpqABZiTiSsjxqjSeWPqf9ft91O+yozJ6FsgEj8qPYb6P+4z52zX1LZ94+lHbuDE9cTfmyg/2P3yJy0PsSliRMBnh4bS8q/OCHvgrG0EQS7tlU7AqHgmXB57gJ/AbASICK+J2kQGAJ2TLZTj4Iws8ZqM5Bry2HvXeAlzaVzF/i1PWl+BpwKIOnXgEHgoal26i4IM2ukCBhN/Ob6zL4mvgu8pMuADRGxFvgg8GlJ76fTBf22iJjyviAOwGbWSJ0uiOK+5E90F/iIuKTr8Wbg5H3ZpwOwmTVWY2fCSVqWzfrYLGmTpIuKrJiZWYrxYWh5tqqktIDHgA9GxG2SFgC3Srq+Z2aImVlFiu2CmAl9B+CI2A5szx7/QtIWOoOVHYDNrBaeF/eEk3Q0cBxw8wTvrQZWAxx5QL0Phpk1R2cURL1vS5/cPpd0APAV4H0R8UTv+xGxJiKGI2J40WC9vw6YWXOMT8Roah8wkubQCb5XR8RXi6mSmVkxGtsFIUnAZ4EtEXF5cVUyM0u3j4vxVCKlT+Bk4K3A6yXdnm3TLkBsZlaWIhdknwkpoyD+D2revjez560IMdbUYWhmZnVX9y6I0gNwp+u478xJZe9KaLAflPiPdDDxPNiduJylBhKG4wykLQd5+6y0uq+YdUBS/jGmXA9lSg/PThvGtHh2wvKrwPbFTyblfzKhl3FkSVLRtBOOexGeC33AbgGbWWM5AJuZVaDgBdlnhAOwmTVWY8cBm5nVWQSMFbQg+0xxADazxnIXhJlZBdwHbGZWoXAANjOrhi/CmZlVIMJ9wGZmFREtj4IwM6uG+4DNzCrgtSDMzKoSnX7gOnMANrPG8igIM7MKhC/CTaDCrwSRVHjaurADif+Ilbqyf8qv3kor+7Ck3DA6J2094oNau/vOq2gllZ3qiHZa/gfV/wc/mnjOJla9EO6CMDOriEdBmJlVIMIB2MysMh6GZmZWkcb3AUuaBWwAtkXEG9OrZGaWLhDtmo+CKKJ2FwFbCtiPmVmhIudWlaQALGkp8NvAZ4qpjplZQbKLcHm2PCStlHSXpK2SLp4kzR9K2ixpk6T/mG6fqV0Qfwt8GFgwWQJJq4HVAEceUO+vA2bWMAU1b7Ou1iuA04ER4BZJayNic1eaFcBHgZMj4lFJ0w6B7zsiSnojsCMibp0qXUSsiYjhiBheNFjvK5Jm1iwFtoBPALZGxL0RsQe4BljVk+ZdwBUR8Win7Ngx3U5TmqQnA2dL+klWmddL+veE/ZmZFSaAdlu5NmBI0oaubXXP7pYA93c9H8le6/YS4CWSvivpJkkrp6tj310QEfFROs1tJJ0CfCgi3tLv/szMChVA/nHAOyNiOLHE2cAK4BRgKfAdSb8REY9NlsGdsmbWWBH5thy2Acu6ni/NXus2AqyNiNGIuA/4MZ2APKlCAnBE3OgxwGZWO8WNQ7sFWCFpuaS5wLnA2p40X6fT+kXSEJ0uiXun2qlnwplZQ+UfYjadiBiTdCGwns7SiFdFxCZJlwEbImJt9t4ZkjYDLeDPIuLhqfbrAGxmzVXgLIuIWAes63ntkq7HAXwg23IpPQCnHI/U/2XzknKnfZL7Jy6OOjtxddWxVv/51Ur73V80MJaU/yez+1/PF2BR9F/+LvZLKvvpdtp6wo89cnBS/l0JH10sSiq60hlm4xWIdr2HvroFbGYN5gBsZlaNypvhU3MANrPmcgA2M6vAvk3EqIQDsJk1VuMXZDczqy2PgjAzq4bcAjYzq0DVt7vIwQHYzBpKvghnZlYZt4DNzCqSuATATHMANrNm8jhgM7PqeBSEmVlVah6AfUsiM7OKlNoCbhPsYrTv/PMTe9TnRv/5dyf2JY0klA0wkJj/l/S/Ju68hLwA7bG0us/XrqT8tyccu/kMJpW9J/HYvUiJ6wkf/Iu+8/54+6yksvckLgX5dFLuDndBmJlVIfBUZDOzyrgFbGZWDXdBmJlVpeYBOGkUhKSDJF0r6UeStkg6qaiKmZkli5xbRVJbwH8HfCsizpE0F9i/gDqZmSVTNLgLQtJC4DXA2wAiYg+wp5hqmZkVoOajIFK6IJYDDwH/KukHkj4jaX5vIkmrJW2QtGHn0zX/d2RmjTLeCp5uq0pKAJ4NHA9cGRHHAU8CF/cmiog1ETEcEcNDg/X+b2RmDVPzPuCUADwCjETEzdnza+kEZDOz6uVs/T4nW8AR8QBwv6SXZi+dCmwupFZmZkWoeQs4dRTEe4GrsxEQ9wJvT6+SmVkx1OQF2SPidmC4oLqYmT2veCacmTVXzQdeOQCbWTM1eSJGP4Kg3U5Y37TV/1rCAHMTPozRxPWA70xcF1akrQv7eEJn2FBi3ecPpK37f9/stL+ilw/0f+x2DKT97k8krH8NEK2dSfkfYW7feeckrkUs1WDYqQOwmVlFHIDNzMon6j8KwveEM7NmKngihqSVku6StFXSr8z67Ur3+5JC0rQjxByAzay5CpqIIWkWcAVwJnAMcJ6kYyZItwC4CLi5972JOACbWXMVNxPuBGBrRNybrfx4DbBqgnR/AfwVOe8p6gBsZo21D10QQ+OrNmbb6p5dLQHu73o+kr32TFnS8cCyiPivvPXzRTgza678oyB2RkTfs3olDQCXk62PnpcDsJk1UxQ6CmIbsKzr+dLstXELgGOBG7Pxz4uBtZLOjogNk+3UAdjMmqu4ccC3ACskLacTeM8F3rS3mIjHgaHx55JuBD40VfAF9wGbWYMVNQwtIsaAC4H1wBbgSxGxSdJlks7ut35uAZtZcxU4Ey4i1gHrel67ZJK0p+TZpwOwmTVTxYut5+EAbGaNJLwamplZZRyAzcyq4gD8jHbAL1v9D8xbkDqmr9X/+qYtzUoq+qmk3EDKOsrA/Oj/4AVpB35eO21d2MXttPJTlhNW4hrUY4mf25EDaRHk8Vb/+dPOeGglNj8fSCwfcAA2M6uE74hhZlYhB2Azs2o0ekF2Se+XtEnSRklflDRYVMXMzFIVuSD7TOg7AEtaAvwpMBwRx9Lpsz+3qIqZmSXJuxZwhQE4tQtiNrCfpFFgf+Dn6VUyMytIzfuA+24BR8Q24G+AnwHbgccj4rredJJWjy9y/PDTNT8aZtYY4zPhmtoFcTCdW3IsB14AzJf0lt50EbEmIoYjYvjQwbTxoGZm+0LtyLVVJeUi3GnAfRHxUESMAl8FXlVMtczMEjW8D/hnwCsl7U9notepwJSLD5uZlanuEzFS+oBvBq4FbgPuzPa1pqB6mZmla3ALmIi4FLi0oLqYmRWq7i1gz4Qzs+ZyADYzq0Cxd0WeEeUuR4nYlbLIXaTdQ3Qg+i870lYVZNdTaf+KI9KG8EXSsUsre07icpSthCUVAXYn5B9spdV9tD0nKf+OxCFShz02v++8iYedpysOfr4jhplZlaLeEdgB2Mwayy1gM7Mq+K7IZmbV8UU4M7OKOACbmVUh8EU4M7Oq+CKcmVlVHIDNzMrniRhmZlWJahdbz8MB2Myaq97x1wHYzJrLXRBmZlUIwF0QZmYVqXf8Tbopp5lZrRV5W3pJKyXdJWmrpIsneP8DkjZLukPSDZKOmm6fpbaA5yKObM/rfwejafMK2+3+1wN+ciypaGJ22rqwYwl1B9h/d0r5ac2IPWNpp9nOpNxww2j/59yx7f2Syj4kcSHpnyd2Yi5KWMs59bjvScxfhKJGQUiaBVwBnA6MALdIWhsRm7uS/QAYjohdkv4E+Gvgj6bar1vAZtZMxd6W/gRga0TcGxF7gGuAVc8qLuLbEbEre3oTsHS6nboP2MwaqTMRI3cLeEjShq7nayKi+y7vS4D7u56PACdOsb8LgG9OV6gDsJk1V/5ey50RMVxEkZLeAgwDr50urQOwmTXWPrSAp7MNWNb1fGn22rPLk04DPga8NiJ2T7fTafuAJV0laYekjV2vHSLpekl3Zz8PzvUrmJmVpdg+4FuAFZKWS5oLnAus7U4g6TjgX4CzI2JHnp3muQj3OWBlz2sXAzdExArghuy5mVmNdNaCyLNNu6eIMeBCYD2wBfhSRGySdJmks7NknwAOAL4s6XZJayfZ3V7TdkFExHckHd3z8irglOzx54EbgY9M+1uYmZWpwAXZI2IdsK7ntUu6Hp+2r/vstw/48IjYnj1+ADh8soSSVgOrAY6c71FvZlaSqP8tiZIjYkRM2YsSEWsiYjgihocG+x8Ubma2zyLybRXpNwA/KOkIgOxnrg5nM7NSFXcRbkb0G4DXAudnj88HvlFMdczMiqN2O9dWlTzD0L4IfA94qaQRSRcAfwmcLulu4LTsuZlZfQSdiRh5torkGQVx3iRvnVpwXczMCiOiyIkYM8Iz4cysuRyAzcwq4gD8jECMqf91beck5O1UoP9f98A9aR/k61oJ6yADT5OWf35rbv+ZI21N3Cfbg0n5l7XS8i9s9f+5j6QcN2Cx0haS3m/gwKT8Ow55ou+8o4ljm0bTsqcb7wOuMbeAzayxqhzhkIcDsJk1VLWTLPJwADazZgocgM3MKlPvHggHYDNrLo8DNjOrigOwmVkFIqBV7z4IB2Azay63gM3MKuIAbGZWgQBy3O+tSg7AZtZQAeE+YDOz8gW+CGdmVhn3AZuZVcQB2MysCvVfjEdRYgUlPQT8dIokQ8DOkqqzr1y3/tW5fnWuG9S7fjNdt6MiYlG/mRfOOSxeNfQHudJ+64F/ujUihvstq1/lLsg+zcGUtKGKg5CH69a/OtevznWDetevznXbq+YtYHdBmFlDeSqymVk1AsLjgPfJmqorMAXXrX91rl+d6wb1rl+d69ZR85lwpV6EMzMry8LZi+KkBatypV3/2GebfxHOzKw0EVDzm3IOlF2gpJWS7pK0VdLFE7w/T9J/Zu/fLOnoEuu2TNK3JW2WtEnSRROkOUXS45Juz7ZLSqzfTyTdmZW7YYL3Jenvs2N3h6TjS6zbS7uOye2SnpD0vp40pR07SVdJ2iFpY9drh0i6XtLd2c+DJ8l7fpbmbknnl1i/T0j6UfbZfU3SQZPknfI8mKG6fVzStq7P7qxJ8k759126iHxbRUoNwJJmAVcAZwLHAOdJOqYn2QXAoxHxYuBTwF+VWMUx4IMRcQzwSuA9E9QP4H8j4uXZdlmJ9QN4XVbuRF+XzgRWZNtq4MqyKhURd40fE+AVwC7gaxMkLevYfQ5Y2fPaxcANEbECuCF7/iySDgEuBU4ETgAunSxQz0D9rgeOjYjfBH4MfHSK/FOdBzNRN4BPdX1263rfzPn3XaIgWq1cW1XKbgGfAGyNiHsjYg9wDdDbSbMK+Hz2+FrgVEkqo3IRsT0ibsse/wLYAiwpo+yCrAL+LTpuAg6SdEQF9TgVuCcippp0M6Mi4jvAIz0vd59bnwd+Z4KsbwCuj4hHIuJROkFxomBUeP0i4rqIGMue3gQsLbrcPCY5dnnk+fsuz/hylHm2ipQdgJcA93c9H+FXA9zeNNnJ+DhwaCm165J1fRwH3DzB2ydJ+qGkb0r69RKrFcB1km6VtHqC9/Mc3zKcC3xxkveqOnYAh0fE9uzxA8DhE6SpyzF8B/DNSd6b7jyYKRdm3SNXTfKtoC7H7hnRzrdVpPQ+4OcCSQcAXwHeFxFP9Lx9G50pkr8F/APw9RKr9uqIOJ7OV7z3SHpNiWXnImkucDbw5QnervLYPUt0hv/UcgiQpI/R6Q67epIkVZwHVwIvAl4ObAc+WUKZSQKIduTa8piJ61dlB+BtwLKu50uz1yZMI2k2sBB4uJTadcqcQyf4Xh0RX+19PyKeiIhfZo/XAXMkDZVRt4jYlv3cQad/9YSeJHmO70w7E7gtIh7sfaPKY5d5cLxLJvu5Y4I0lR5DSW8D3gi8OSYZI5rjPChcRDwYEa3ozGz49CRl1uH8e0ZEYS3gmbp+VXYAvgVYIWl51lI6F1jbk2YtMH7l+RzgfyY7EYuW9TV/FtgSEZdPkmbxeJ+0pBPoHMMZ/wchab6kBeOPgTOAjT3J1gJ/nI2GeCXweNdX7rKcxyTdD1Uduy7d59b5wDcmSLMeOEPSwdnX7DOy12acpJXAh4GzI2LXJGnynAczUbfuawm/O0mZef6+S1XgRbiZuX4VEaVuwFl0rvDeA3wse+0yOicdwCCdr69bge8DLyyxbq+m883lDuD2bDsLeDfw7izNhcAm4Id0LpS8qqS6vTAr84dZ+ePHrrtuovNf+h7gTmC45M92Pp2AurDrtUqOHZ1/AtuBUTp9kRfQuZZwA3A38N/AIVnaYeAzXXnfkZ1/W4G3l1i/rXT6UMfPvX/O0r4AWDfVeVBC3b6QnVN30AmqR/TWLXv+K3/fVW3At4ANObeNPc9X9+zrnJ5z5K3AP/ak2Qgs7Xp+DzA0VR09E87MbBqSzgFWRsQ7s+dvBU6MiAu70mzM0oxkz+/J0ky6ZKcvwpmZTW9Grl85AJuZTW9Grl95LQgzs2lExJikC+lckJ0FXBURmyRdBmyIiLV0LuB/QdJWOhNZzp1uv+4DNjOriLsgzMwq4gBsZlYRB2Azs4o4AJuZVcQB2MysIg7AZmYVcQA2M6vI/wN+Sh1OuRfo7wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz7l27Lz9S1P"
      },
      "source": [
        "将这些值缩小至 0 到 1 之间，然后将其馈送到神经网络模型。为此，请将这些值除以 255。请务必以相同的方式对*训练集*和*测试集*进行预处理："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW5WzIPlCaWv"
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee638AlnCaWz"
      },
      "source": [
        "为了验证数据的格式是否正确，以及您是否已准备好构建和训练网络，让我们显示*训练集*中的前 25 个图像，并在每个图像下方显示类名称。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZTImqg_CaW1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "cb98cc78-f92c-4b5c-b7f8-ba857db70f0f"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-54389fd111e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'class_names' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHIAAABVCAYAAACVdLDzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAE0UlEQVR4nO2dzW4cRRSFT7Xnx55hnDixrUGBWBAiZcECKU+QXXb8bNnCM/AQSDwHWx6AJRLLCHaAlKDYCZmEYWIyY890dxUbWN1zDY1AwOV8y6vyreo+XZ4zdbtqUikF4r9P9U8PQPw1SMggSMggSMggSMgg9Lo03t9O5WhitU9VNrHSJp5km8fvn/H467tDE2sXW7RtdTCg8eYHO+be/jZt2z7hz3a6bON5aa8bAL6d8nFUvZbG1/XIBkmK9uQEeT6nN6qTkEeTCl+8t2Piw9GZiTULnrrc6tP4+1/xi//07hsmdvrZLm07+vCIxp99bG/U1Q9u0bann9jrA4Dh2/aBWn25om3vfvQajU+u/kTj381um1i5Zr8Wzt99h/49oH+tYZCQQZCQQZCQQehkdgAgMc9EYrlwF1qcR+eQJfFyO464HvJ14y1iAdfgjnPoPNslWae8k7hx2ycuHgAuOX0ew467JZfi3CEAmpFhkJBBkJBBkJBB6GR2EhL6hXzAl9qEmsRT58yfnb7TvpAh7lTcZAz6fFXmYWP73GNrYAAWFR/HvG/NziuFtz1vGhqf0igwaayNWZ3YWNo4CaAZGQYJGQQJGQQJGQQJGYQ/sURHFopIbOUsKJH6LAC33ow1cbOp4oVlVNyJ3tuyOW5uvUTbNmS5DAB+7Nk+pz3unh9PlzS+dObN8TUby2QcDe8OgGZkGCRkECRkECRkECRkEDq7VsfUkWZeQ+dVRq+uzCrRXuqWP5eHJFb3ucO93K6dcfBXGRkv8/oxniQ+8JoVz0m7i269ZmQQJGQQJGQQJGQQOpsd9oHLfIp9wf6iDMDIMQg98rHftLxxYq+eAbhR2ULvgx43NQeFF4VXsEXr88wN0GK+x3M4bqUckBhv6qIZGQQJGQQJGQQJGQQJGYROrjWjYAX76uOYOMtB4c5y7ewJOXbaVyT+AtxZDp14bmyOceKbVO854xjD7nDeOP3dSI6b3fuZxr95bJctN+S7QM3W8n5FMzIIEjIIEjIIEjIIEjIInVxrQUFm64utdbIDZ7Gwdlzr144DTLD9PU/cWe47OcaVfV7v9/gA36q445yR9dpT4uABoLTPaHzubBzqE5fLXjtNTmEa0IwMg4QMgoQMgoQMQrclugK8IEXdCfMeLTcNLTnmBADsaXa/dWrzjJ1ltOIduZKtcZhm3tbxQEjE0DVOYfl6xZM8dwrf7I60xNgs+NAAaEaGQUIGQUIGQUIGQUIGoWNhOWHFPBbZn1EV7k69LRSrM+7oClnSK97JhM4u6T5xra3jINdOfJscZFhnvoV4lnmOw8WYxlmX58RUXzTrNCODICGDICGDICGDICGD0Mm1DpBwPZPtObW1WDlz17rktV8U58yahuQZrb0DZ7hb3DT2MnnpF/i85tuP3sx2E88Vx4I/cgrAB46rZmNhB0E6tw6AZmQYJGQQJGQQJGQQOr5Fl9CQwnCfFYudY6J3N9wI3Gm5yTgne5/HLX8bDYUfhb3Mdt/Gqy3/tbpLLR/3Melzmrj92Kn4j7DNrpzSeD0jMdJOx7P8D5CQQZCQQZCQQZCQQUil/PETXVJKTwF8//cNR/wOR6WwU3k6Cin+vehfaxAkZBAkZBAkZBAkZBAkZBAkZBAkZBAkZBB+AWeURadzZUMIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## 构建模型\n",
        "\n",
        "构建神经网络需要先配置模型的层，然后再编译模型。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxg1XGm0eOBy"
      },
      "source": [
        "### 设置层\n",
        "\n",
        "神经网络的基本组成部分是*层*。层会从向其馈送的数据中提取表示形式。希望这些表示形式有助于解决手头上的问题。\n",
        "\n",
        "大多数深度学习都包括将简单的层链接在一起。大多数层（如 `tf.keras.layers.Dense`）都具有在训练期间才会学习的参数。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ODch-OFCaW4"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(12, 17, 3)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(2)\n",
        "])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gut8A_7rCaW6"
      },
      "source": [
        "该网络的第一层 `tf.keras.layers.Flatten` 将图像格式从二维数组（28 x 28 像素）转换成一维数组（28 x 28 = 784 像素）。将该层视为图像中未堆叠的像素行并将其排列起来。该层没有要学习的参数，它只会重新格式化数据。\n",
        "\n",
        "展平像素后，网络会包括两个 `tf.keras.layers.Dense` 层的序列。它们是密集连接或全连接神经层。第一个 `Dense` 层有 128 个节点（或神经元）。第二个（也是最后一个）层会返回一个长度为 10 的 logits 数组。每个节点都包含一个得分，用来表示当前图像属于 10 个类中的哪一类。\n",
        "\n",
        "### 编译模型\n",
        "\n",
        "在准备对模型进行训练之前，还需要再对其进行一些设置。以下内容是在模型的*编译*步骤中添加的：\n",
        "\n",
        "- *损失函数* - 用于测量模型在训练期间的准确率。您会希望最小化此函数，以便将模型“引导”到正确的方向上。\n",
        "- *优化器* - 决定模型如何根据其看到的数据和自身的损失函数进行更新。\n",
        "- *指标* - 用于监控训练和测试步骤。以下示例使用了*准确率*，即被正确分类的图像的比率。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhan11blCaW7"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "## 训练模型\n",
        "\n",
        "训练神经网络模型需要执行以下步骤：\n",
        "\n",
        "1. 将训练数据馈送给模型。在本例中，训练数据位于 `train_images` 和 `train_labels` 数组中。\n",
        "2. 模型学习将图像和标签关联起来。\n",
        "3. 要求模型对测试集（在本例中为 `test_images` 数组）进行预测。\n",
        "4. 验证预测是否与 `test_labels` 数组中的标签相匹配。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4P4zIV7E28Z"
      },
      "source": [
        "### 向模型馈送数据\n",
        "\n",
        "要开始训练，请调用 `model.fit` 方法，这样命名是因为该方法会将模型与训练数据进行“拟合”："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvwvpA64CaW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03ed9cb3-c678-47e1-d2a3-1539da2a5c2e"
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=15)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.8200\n",
            "Epoch 2/15\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7600\n",
            "Epoch 3/15\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7300\n",
            "Epoch 4/15\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7800\n",
            "Epoch 5/15\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7800\n",
            "Epoch 6/15\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8600\n",
            "Epoch 7/15\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8600\n",
            "Epoch 8/15\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8200\n",
            "Epoch 9/15\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.8300\n",
            "Epoch 10/15\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.9100\n",
            "Epoch 11/15\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7500\n",
            "Epoch 12/15\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8300\n",
            "Epoch 13/15\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8000\n",
            "Epoch 14/15\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8000\n",
            "Epoch 15/15\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.8300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9c47dd7240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3ZVOhugCaXA"
      },
      "source": [
        "在模型训练期间，会显示损失和准确率指标。此模型在训练数据上的准确率达到了 0.91（或 91%）左右。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCpr6DGyE28h"
      },
      "source": [
        "### 评估准确率\n",
        "\n",
        "接下来，比较模型在测试数据集上的表现："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VflXLEeECaXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56a9f95a-605c-410b-e232-8d8b0529baad"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 - 0s - loss: 0.3099 - accuracy: 0.9130\n",
            "\n",
            "Test accuracy: 0.9130434989929199\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWfgsmVXCaXG"
      },
      "source": [
        "结果表明，模型在测试数据集上的准确率略低于训练数据集。训练准确率和测试准确率之间的差距代表*过拟合*。过拟合是指机器学习模型在新的、以前未曾见过的输入上的表现不如在训练数据上的表现。过拟合的模型会“记住”训练数据集中的噪声和细节，从而对模型在新数据上的表现产生负面影响。有关更多信息，请参阅以下内容：\n",
        "\n",
        "- [演示过拟合](https://tensorflow.google.cn/tutorials/keras/overfit_and_underfit#demonstrate_overfitting)\n",
        "- [避免过拟合的策略](https://tensorflow.google.cn/tutorials/keras/overfit_and_underfit#strategies_to_prevent_overfitting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-PyD1SYE28q"
      },
      "source": [
        "### 进行预测\n",
        "\n",
        "在模型经过训练后，您可以使用它对一些图像进行预测。模型具有线性输出，即 [logits](https://developers.google.com/machine-learning/glossary#logits)。您可以附加一个 softmax 层，将 logits 转换成更容易理解的概率。 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnfNA0CrQLSD"
      },
      "source": [
        "probability_model = tf.keras.Sequential([model, \n",
        "                                         tf.keras.layers.Softmax()])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl91RPhdCaXI"
      },
      "source": [
        "predictions = probability_model.predict(test_images)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Kk1voUCaXJ"
      },
      "source": [
        "在上例中，模型预测了测试集中每个图像的标签。我们来看看第一个预测结果："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DmJEUinCaXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f41c647-f619-4306-a2f3-3f8203e1df26"
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.1695184, 0.8304816], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hw1hgeSCaXN"
      },
      "source": [
        "预测结果是一个包含 10 个数字的数组。它们代表模型对 10 种不同服装中每种服装的“置信度”。您可以看到哪个标签的置信度值最大："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsqenuPnCaXO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd335103-49cc-43f8-f293-3c20e742e839"
      },
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E51yS7iCCaXO"
      },
      "source": [
        "因此，该模型非常确信这个图像是短靴，或 `class_names[9]`。通过检查测试标签发现这个分类是正确的："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd7Pgsu6CaXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7578c76b-6e1f-4f81-9f33-b0d84f98003d"
      },
      "source": [
        "test_labels[0]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygh2yYC972ne"
      },
      "source": [
        "您可以将其绘制成图表，看看模型对于全部 10 个类的预测。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvYmmrpIy6Y1"
      },
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(10))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh9yABaME29S"
      },
      "source": [
        "### 验证预测结果\n",
        "\n",
        "在模型经过训练后，您可以使用它对一些图像进行预测。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Ov9OFDMmOD"
      },
      "source": [
        "我们来看看第 0 个图像、预测结果和预测数组。正确的预测标签为蓝色，错误的预测标签为红色。数字表示预测标签的百分比（总计为 100）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV5jw-5HwSmO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "166f1d82-6970-452c-eb01-3d50aa96eb6e"
      },
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i],  test_labels)\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-69392c8b20c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplot_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplot_value_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-c60bdf234dfe>\u001b[0m in \u001b[0;36mplot_image\u001b[0;34m(i, predictions_array, true_label, img)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'red'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n\u001b[0m\u001b[1;32m     16\u001b[0m                                 \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                 class_names[true_label]),\n",
            "\u001b[0;31mNameError\u001b[0m: name 'class_names' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko-uzOufSCSe"
      },
      "source": [
        "i = 12\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i],  test_labels)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgdvGD52CaXR"
      },
      "source": [
        "让我们用模型的预测绘制几张图像。请注意，即使置信度很高，模型也可能出错。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQlnbqaw2Qu_"
      },
      "source": [
        "# Plot the first X test images, their predicted labels, and the true labels.\n",
        "# Color correct predictions in blue and incorrect predictions in red.\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions[i], test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions[i], test_labels)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R32zteKHCaXT"
      },
      "source": [
        "## 使用训练好的模型\n",
        "\n",
        "最后，使用训练好的模型对单个图像进行预测。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRJ7JU7JCaXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e26b5ea-b8fc-4df1-ef40-6819a8c8061e"
      },
      "source": [
        "# Grab an image from the test dataset.\n",
        "img = test_images[1]\n",
        "\n",
        "print(img.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12, 17, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz3bVp21CaXV"
      },
      "source": [
        "`tf.keras` 模型经过了优化，可同时对一个*批*或一组样本进行预测。因此，即便您只使用一个图像，您也需要将其添加到列表中："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDFh5yF_CaXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1cf7f73-fd37-4197-9050-eba42d875c43"
      },
      "source": [
        "# Add the image to a batch where it's the only member.\n",
        "img = (np.expand_dims(img,0))\n",
        "\n",
        "print(img.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 12, 17, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ5wLTkcCaXY"
      },
      "source": [
        "现在预测这个图像的正确标签："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_rzNSdrCaXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acdd054d-392b-451e-bcc1-fd4e5a79bbfa"
      },
      "source": [
        "predictions_single = probability_model.predict(img)\n",
        "\n",
        "print(predictions_single)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.26764467 0.7323553 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ai-cpLjO-3A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "outputId": "464f5ea8-b4dd-4566-c7b9-0bcb818da716"
      },
      "source": [
        "plot_value_array(1, predictions_single[0], test_labels)\n",
        "_ = plt.xticks(range(10), class_names, rotation=45)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-44b18fa113d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_value_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_single\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-c60bdf234dfe>\u001b[0m in \u001b[0;36mplot_value_array\u001b[0;34m(i, predictions_array, true_label)\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mthisplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"#777777\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[1;32m   2407\u001b[0m     return gca().bar(\n\u001b[1;32m   2408\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2409\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2340\u001b[0m         x, height, width, y, linewidth = np.broadcast_arrays(\n\u001b[1;32m   2341\u001b[0m             \u001b[0;31m# Make args iterable too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2342\u001b[0;31m             np.atleast_1d(x), height, width, y, linewidth)\n\u001b[0m\u001b[1;32m   2343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[0;31m# Now that units have been converted, set the tick locations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(subok, *args)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m# consistently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU1Y2OAMCaXb"
      },
      "source": [
        "`keras.Model.predict` 会返回一组列表，每个列表对应一批数据中的每个图像。在批次中获取对我们（唯一）图像的预测："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tRmdq_8CaXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6170587c-7cf4-4022-e46f-293abe15600d"
      },
      "source": [
        "np.argmax(predictions_single[0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFc2HbEVCaXd"
      },
      "source": [
        "该模型会按照预期预测标签。"
      ]
    }
  ]
}